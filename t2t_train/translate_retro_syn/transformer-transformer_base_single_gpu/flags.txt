--autotune_max_trials=10
--autotune_maximize
--autotune_parallel_trials=1
--nocloud_mlengine
--cloud_tpu_name=ubuntu-tpu
--eval_steps=100
--nogenerate_data
--inter_op_parallelism_threads=0
--intra_op_parallelism_threads=0
--iterations_per_loop=100
--log_step_count_steps=100
--master=
--output_dir=./t2t_train/translate_retro_syn/transformer-transformer_base_single_gpu
--noprofile
--schedule=continuous_train_and_eval
--tmp_dir=/tmp/t2t_datagen
--tpu_num_shards=8
--nouse_tpu
--nouse_tpu_estimator
--noxla_compile
--timit_paths=
--parsing_path=
--data_dir=./t2t_data
--nodbgprofile
--decode_hparams=
--noenable_graph_rewriter
--eval_early_stopping_metric=loss
--eval_early_stopping_metric_delta=0.1
--eval_early_stopping_metric_minimize
--noeval_run_autoregressive
--eval_throttle_seconds=600
--noeval_use_test_set
--noexport_saved_model
--gpu_order=
--hparams=batch_size=6144, hidden_size=256, layer_prepostprocess_dropout=0.3,
--hparams_set=transformer_base_single_gpu
--keep_checkpoint_every_n_hours=10000
--keep_checkpoint_max=20
--local_eval_frequency=100
--nolocally_shard_to_cpu
--nolog_device_placement
--model=transformer
--problem=translate_retro_syn
--ps_gpu=0
--ps_job=/job:ps
--ps_replicas=0
--noregistry_help
--save_checkpoints_secs=0
--nosync
--notfdbg
--train_steps=2000000
--worker_gpu=1
--worker_gpu_memory_fraction=0.95
--worker_id=0
--worker_job=/job:localhost
--worker_replicas=1
--nohelp
--nohelpfull
--nohelpshort
